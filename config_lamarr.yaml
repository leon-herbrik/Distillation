trainer:
  batch_size: 32
  seed: 42
  pl_trainer:
    limit_train_batches: 500
    limit_val_batches: 100
    max_epochs: 100
dataset:
  target_feature_path: '/data/mokhtarzadeh/GroundVQA/data/unified/egovlp_internvideo_subsampled.hdf5'
  input_feature_path: '/data/mokhtarzadeh/vqgancodes/vqgan_codes_nlq_train_val_test.hdf5'
  split_index_path: '~/leon/Distillation/dataset/split_ids.json'
model:
  img_size: 256
  seq_len: 256
  hidden_dim: 1280
  codebook_size: 1024
  depth: 16
  heads: 8
  lr: 1.0e-4
  mlp_dim: 3072
  dropout: 0.1
  nclass: 0
  special_tokens:
    - '[feat]'
    - '[mask]'
  last_linear_dim: 2304
  loss: 'mae'
  vqgan_embedding_path: '~/leon/GroundVQA/checkpoints/vqgan/embeddings.pth'
  transformer_embedding_path: '~/leon/GroundVQA/checkpoints/transformer/embeddings.pth'
logger:
  project: 'Distillation-debug'
